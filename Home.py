import openai
from utils.llm_faiss import run_llm
import streamlit as st
from pathlib import Path
import json

# OpenAI APIã‚­ãƒ¼è¨­å®š
openai.api_key = st.secrets["OPENAI_API_KEY"]


def load_vectorstore_config():
    """
    JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ vectorstore ã®è¨­å®šã‚’èª­ã¿è¾¼ã‚€
    """
    config_path = Path("config/vectorstore.json")
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        st.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
        return {}
    except json.JSONDecodeError:
        st.error(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“: {config_path}")
        return {}

def vectorstore_dir(stock):
    """
    é¸æŠã•ã‚ŒãŸå›³æ›¸ã«å¯¾å¿œã™ã‚‹ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®ãƒ‘ã‚¹ã‚’è¿”ã™
    """
    config = load_vectorstore_config()
    return config.get(stock, "")


# header
st.header("chatbot-himejiğŸ¦œğŸ”—")

# sidebar
with st.sidebar:
    stock = st.radio(
        label="å¯¾è±¡å›³æ›¸ã‚’é¸æŠã—ã¦ãã ã•ã„",
        options=(
            "åœŸæœ¨å·¥äº‹å…±é€šä»•æ§˜æ›¸",
            "åœŸæœ¨è«‹è² å·¥äº‹å¿…æº",
            "è¦ç¨‹é›†ã€é“è·¯â… ç·¨ã€‘",
            "è¦ç¨‹é›†ã€é“è·¯â…¡ç·¨ã€‘",
            "è¦ç¨‹é›†ã€æ²³å·ç·¨ã€‘",
            "è¦ç¨‹é›†ã€ç ‚é˜²ç·¨_ç ‚é˜²ã€‘",
            "è¦ç¨‹é›†ã€ç ‚é˜²ç·¨_æ€¥å‚¾æ–œã€‘",
            "è¦ç¨‹é›†ã€ç ‚é˜²ç·¨_åœ°ã™ã¹ã‚Šã€‘",
            "åœ°æ•´ä¾¿è¦§ã€åœŸæœ¨å·¥äº‹å…±é€šç·¨ã€‘",
            "åœ°æ•´ä¾¿è¦§ã€é“è·¯ç·¨ã€‘",
            "åœ°æ•´ä¾¿è¦§ã€æ²³å·ç·¨ã€‘",
            "é“è·¯æ§‹é€ ä»¤",
            "æ²³å·ç®¡ç†äº‹å‹™å¿…æº",
            "æ²³å·ç®¡ç†æ–½è¨­ç­‰æ§‹é€ ä»¤",
        ),
        index=0,
    )

    st.subheader("Link")
    st.markdown("""
    * [OpenAI API](https://platform.openai.com)
    * [LangChain](https://python.langchain.com/docs/introduction/)
    * [streamlit](https://streamlit.io/)
    """)

VECTORSTORE_DIR = vectorstore_dir(stock)

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "assistant", "content": "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"}
    ]

if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    response = run_llm(
        query=prompt,
        vectordir=VECTORSTORE_DIR,
        chat_history=st.session_state["chat_history"],
    )
    msg = response["answer"]
    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.session_state.chat_history.append((prompt, response["answer"]))
    st.chat_message("assistant").write(msg)
